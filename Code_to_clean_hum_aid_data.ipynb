{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0cntpErJY3NcK/WNPwgKx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/550tealeaves/DATA-70500-working-with-data/blob/main/Code_to_clean_hum_aid_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyUcDe-G7cgX"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the flatfile path (csv) to a variable\n",
        "in_flatfile = \"G:/My Drive/DVS/Mentorship 2025 Summer Cohort/Humanitarian Aid Tool/data/in/Sudan Indicators.csv\""
      ],
      "metadata": {
        "id": "TkBKX9N17km2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the shapefile path to a variable\n",
        "in_shapefile = \"G:/My Drive/DVS/Mentorship 2025 Summer Cohort/Humanitarian Aid Tool/geo/Sudan/sdn_adm_cbs_nic_ssa_20200831_shp.zip\""
      ],
      "metadata": {
        "id": "uN7Wnjug7lld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the output shapefile path a name and variable\n",
        "output_shapefile_path = \"G:/My Drive/DVS/Mentorship 2025 Summer Cohort/Humanitarian Aid Tool/data/out/Sudan_Indicators_Merged.shp\""
      ],
      "metadata": {
        "id": "XsT5ZGi27nbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Begin parsing the flatfile"
      ],
      "metadata": {
        "id": "xS6gZo0C7q1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read csv and load into dataframe\n",
        "df = pd.read_csv(in_flatfile, encoding=\"ISO-8859-1\")\n",
        "print(f\"\\n--- Flatfile Successfully Imported From:\\n{in_flatfile}\")"
      ],
      "metadata": {
        "id": "ukC-jMHQ7uPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print information to review dataframe before cleaning\n",
        "# print(\"\\n\\n--- DataFrame Info Before Cleaned ---\")\n",
        "# print(df.info())"
      ],
      "metadata": {
        "id": "CR4cNCwG7wfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of missing values before clean\n",
        "missing_summary_before = df.isnull().sum()\n",
        "# print(\"\\n\\n--- Missing DataFrame Values Summary Before Clean ---\\n\", missing_summary_before)"
      ],
      "metadata": {
        "id": "_7UcfRT27zKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print first 5 records of dataframe and last 10 records\n",
        "# print(\"\\n--- DataFrame Head (can be any number of records) ---\\n\")\n",
        "# print(df.head())\n",
        "# print(\"\\n--- DataFrame Tail ---\\n\\n\")\n",
        "# print(df.tail(10))"
      ],
      "metadata": {
        "id": "NWxhlQpY71xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize column names to snake_case\n",
        "df.columns = (\n",
        "    df.columns.str.strip()\n",
        "              .str.lower()\n",
        "              .str.replace(\" \", \"_\")\n",
        "              .str.replace(\"+\", \"\", regex=False)\n",
        "              .str.replace(\"#\", \"\", regex=False)\n",
        ")"
      ],
      "metadata": {
        "id": "4UHH4vNl74eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop row 2\n",
        "df = df.drop([0])"
      ],
      "metadata": {
        "id": "d7cz1D4n78F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define columns to be dropped in one place\n",
        "# Get the names of the first 6 columns\n",
        "cols_to_drop_by_pos = df.columns[:6].tolist()"
      ],
      "metadata": {
        "id": "TxW0cSmn7-Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define other columns to drop by name\n",
        "cols_to_drop_by_name = [\n",
        "    \"admin_level\",\n",
        "    \"reference_period_start\",\n",
        "    \"reference_period_end\"\n",
        "]"
      ],
      "metadata": {
        "id": "NqPQ6qsr7_5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the lists and drop all unwanted columns in a single step\n",
        "all_cols_to_drop = cols_to_drop_by_pos + cols_to_drop_by_name\n",
        "df = df.drop(columns=all_cols_to_drop, errors='ignore')"
      ],
      "metadata": {
        "id": "sJ5Knz7I8CXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, drop rows with any remaining missing values\n",
        "df.dropna(how='any', inplace=True)"
      ],
      "metadata": {
        "id": "0KlGSviA8EIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print to review dataframe after cleaning\n",
        "# print(\"\\n\\n--- DataFrame Info After Cleaned ---\")\n",
        "# print(df.info())"
      ],
      "metadata": {
        "id": "jG3pV8AX8F1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_summary_after = df.isnull().sum()\n",
        "# print(\"\\n--- Missing Values Summary After Clean ---\", missing_summary_after)\n",
        "# print(\"\\n--- DataFrame Head After Clean ---\", df.head())"
      ],
      "metadata": {
        "id": "gEotvCCc8HoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Begin parsing the shapefile"
      ],
      "metadata": {
        "id": "bYxIe5zr8Nxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the shapefile and load into dataframe\n",
        "gdf = gpd.read_file(in_shapefile, layer=\"sdn_admbnda_adm2_cbs_nic_ssa_20200831\")\n",
        "print(f\"\\n--- Shapefile Successfully Imported From:\\n{in_shapefile}\")"
      ],
      "metadata": {
        "id": "PfvTu4i98Pjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Print information to review the geospatial dataframe\n",
        "# print(\"\\n\\n--- GeoDataFrame Info Before Cleaned ---\")\n",
        "# print(gdf.info())"
      ],
      "metadata": {
        "id": "0-OpTJZa8Rem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# missing_summary_gdf = gdf.isnull().sum()\n",
        "# print(\"\\n--- Missing Values Summary in GeoDataFrame before cleaning ---\\n\", missing_summary_gdf)"
      ],
      "metadata": {
        "id": "4A9g_w-Q8TFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf.columns = (\n",
        "    gdf.columns.str.strip()\n",
        "              .str.lower()\n",
        "              .str.replace(\" \", \"_\")\n",
        "              .str.replace(\"+\", \"\", regex=False)\n",
        "              .str.replace(\"#\", \"\", regex=False)\n",
        ")"
      ],
      "metadata": {
        "id": "tL4u7BOZ8Vme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define columns to be dropped in one place\n",
        "# Get the names of the first 6 columns\n",
        "cols_to_drop_by_pos = gdf.columns[5:19].tolist()"
      ],
      "metadata": {
        "id": "sYhKI7_48XsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define other columns to drop by name\n",
        "cols_to_drop_by_name = [\n",
        "    \"adm2_ar\"\n",
        "]"
      ],
      "metadata": {
        "id": "CeRBjVO_8ZTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the lists and drop all unwanted columns in a single step\n",
        "all_cols_to_drop = cols_to_drop_by_pos + cols_to_drop_by_name\n",
        "gdf = gdf.drop(columns=all_cols_to_drop, errors='ignore')"
      ],
      "metadata": {
        "id": "9tJ4zErm8az1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print information to review the geospatial dataframe after cleaning\n",
        "# print(\"\\n--- GeoDataFrame Info After Cleaned ---\")\n",
        "# print(gdf.info())"
      ],
      "metadata": {
        "id": "rOwHu24S8cle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_summary_gdf = gdf.isnull().sum()\n",
        "# print(\"\\n--- Missing Values Summary in GeoDataFrame after cleaning ---\", missing_summary_gdf)"
      ],
      "metadata": {
        "id": "CkZIO1Se8ePg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge the two DataFrames"
      ],
      "metadata": {
        "id": "rfI6h2vd8gP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Preparing to Merge ---\")\n",
        "# print(\"Cleaned 'df' columns:\", df.columns)\n",
        "# print(\"Cleaned 'gdf' columns:\", gdf.columns)"
      ],
      "metadata": {
        "id": "HPK7Vzq88jR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the merge on the common key\n",
        "merged_gdf = gdf.merge(\n",
        "    df,\n",
        "    how='left',              # Keep all the geographic shapes\n",
        "    left_on='adm2_pcode',    # The key from the GeoDataFrame\n",
        "    right_on='admin2_code'  # The key from the regular DataFrame\n",
        ")"
      ],
      "metadata": {
        "id": "QZuYEyp28lJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Merge Complete ---\")\n",
        "# print(\"Cleaned 'gdf' columns:\", merged_gdf.columns)"
      ],
      "metadata": {
        "id": "nvFpUOOn8nD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary fields\n",
        "gdf = merged_gdf.drop(['admin2_code', 'admin2_name'], axis=1)\n",
        "# print(gdf.info())"
      ],
      "metadata": {
        "id": "xDKAC-hW8oyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename Columns\n",
        "gdf.columns = ['shp_len', 'shp_area', 'adm2', 'adm2_pcode', 'geometry', 'adm1', 'org_acr', 'org', 'org_desc', 'sec_code', 'sec']"
      ],
      "metadata": {
        "id": "oXKs_bJi8qY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspect the Final Merged Data"
      ],
      "metadata": {
        "id": "srWIH-sv8tDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"\\n\\n--- Final Merged GeoDataFrame Info ---\")\n",
        "# print(gdf.info())\n",
        "# print(\"\\n--- Final Merged GeoDataFrame Head ---\")\n",
        "# print(gdf.head())"
      ],
      "metadata": {
        "id": "zexp72u18vrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the GeoDataFrame to a shapefile.\n",
        "# The driver 'ESRI Shapefile' is specified for clarity.\n",
        "gdf.to_file(output_shapefile_path, driver='ESRI Shapefile')"
      ],
      "metadata": {
        "id": "WsDCaSnY8xNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n--- Successfully exported the merged shapefile to:\\n{output_shapefile_path}\")"
      ],
      "metadata": {
        "id": "VMHkO21-8zEQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}